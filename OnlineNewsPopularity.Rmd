---
title: "Online News Popularity Data Set "
author: "Bhupesh Joshi"
output:
  html_document:
    theme: united
    code_folding: hide
    toc: yes
    toc_float:
      collapsed: yes
      smooth_scroll: no
  mainfont: arial
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE )
```


```{r echo=FALSE, results="asis"}
cat("
<style>
#TOC {
  margin: 150px 0px 20px 0px;
}
h1 {
   color: #ff0000;
   font-family: arial;
 }
h2 {
   color: #ff0000;
   font-family: arial;
 }
h3 {
   color: #ff0000;
   font-family: arial;
}
h4 {
   color: #ff0000;
   font-family: arial;
}
h5 {
   color: #ff0000;
   font-family: arial;
}
table.dataTable tbody tr.odd { background-color: red; border:1px #ff0000; }
table.dataTable tbody tr.even { background-color: white; border:1px #ffffff;}


</style>
<style>
body {
text-align: justify}
</style>
")
```

## **1. Introduction**

This growing popularity of online news has made the space very competative. From authors to websites to advertisers, every one wants to precit the popularity of an article before investing their resources to that article. This prediction is perticularly helpful for website as well as social media workers(authors, advertisers etc). The pricing model for advertiser can also take improve if a predictive is at place for the popularity of the article.

The primary aim of the document is to provide an approach to develope an Intelligent Decision Support Systems (IDSS) that analyzes online news
prior to their publication. We plan to do so by accurately predict the popularity of news prior to its publication. Popularity is often measured by considering the number of interactions in the Web and social networks (e.g., number of shares, likes and comments).

## ** 2. Data Used**

### ** 2.1 Data Collection **

The dataset used is provided by UCI machine learning repository, originally acquired and preprocessed by K.Fernandes et al. It extracts 59 attributes
(Predictors + Response) describing different aspects of each article, from a total of 39644 articles published in two years (January 7 2013 to January 7 2015) from Mashable website.

### ** 2.2 Features **

The data contains 58 predictive features and 1 target. The predictive features can be broadly classified into 7 categories. The division of these category is based on the pre-processing done by K.Fernandes et al.

The categories of variables present are: 
* Words : Number of words of the title/content;Average word length;Rate of unique/non-stop words of contents
* Links:  Number of links;Number of links to other articles in Mashable
* Digital Media: Number of images/videos
* Publication Time: Day of the week/weekend
* Keywords: Number of keywords;Worst/best/average keywords (#shares);Article category
* Natural Languaage Processing: Closeness to five LDA topics;Title/Text polarity/subjectivity;Rate and polarity of positive/negative words;Absolute subjectivity/polarity level
* Target: Number of shares at Mashable

Each of these feature categories contain multiple feature they represent different items under that feature class.

## **3. Explanatory Data Analysis**

### **3.1	Feature Types**

A primary data analysis was performed through visual inspection of the training data-set to identify the different types of variables among Continuous, Categorical (Nominal and Ordinal) and Dummy (Binary/Indicator) variables. This analysis helps us identify the choice of feature selection and reduction algorithms in the next stage of modelling.
&nbsp;

The data contains 45 continous features (including target) and 14 dummy variables. The dummy features are either from the time category or data channel category. There are no missing values in the data.

### **3.2	Distribution of Target**

The target is defined as the number of share an article recieves. It is a continous feature with high degree of right skewness. From the distribution presented below it is evident that the there are very less articles for very high number of shares.

```{r echo=TRUE, warning=FALSE,message=FALSE,error=FALSE,fig.keep='all'}
temp_melt<-melt(sharing_data[,"shares"])
p<-ggplot(temp_melt,aes(value))+geom_density(alpha = 0.5)+ggtitle("Density Plots")
ggplotly(p)%>%
  layout(plot_bgcolor="transparent",paper_bgcolor= "transparent")
```

The mean of the data is `r mean(sharing_data$stares)` where as the variance is `r sd(sharing_data$shares)^2`. The range for number of share an article recieves is `r range(sharing_data$shares)`.

### ** Continous Variable** 

#### **Word Features** {.tabset .tabset-fade}

There are 5 words features which denote the number and rate of words in title and the content.

##### **Box Plots** {.tabset .tabset-fade}

The box plots enable visualization of the data-set especially in relation to outliers. However considering the large number of data we will plot box plots category wise.

```{r echo=TRUE, warning=FALSE,message=FALSE,error=FALSE,fig.keep='all'}
word_Data<- conti_data[,c(1:5,10)]
plot_ly( data=melt(word_Data), type = "box",
            split = ~variable,y = ~value)%>%
  layout( title = "Box-Plots of variables")
```

Accept "n_token_content" which tells us the Number of words in the content and "n_token_title" which tells us the Number of words in the title no other variable is well distributed in the entire range. However there is a single outlier present for each of the other variable. Removing that variable gives a good spread to the data. Before removing the observation we will analyse the density plot of word variable.

##### **Density Plots**

The density plots help visualize the characteristics of the distribution including statistical metrics such as mean, standard deviation and kurtosis. It also enables us to visually identify if any relationship exists with the response variable.

```{r echo=TRUE, warning=FALSE,message=FALSE,error=FALSE,fig.keep='all'}

plt<-htmltools::tagList()
index = 1
for (i in colnames(word_Data)){
  p<-ggplot(sharing_data,aes(i, fill = "blue"))+geom_density(alpha = 0.5)+ggtitle(paste0("Density Plots of ",i))
ggplotly(p)%>%
  layout(plot_bgcolor="transparent",paper_bgcolor= "transparent")
plt[index]
index = index+1
}
plt
```

We can draw the same conclusion from the density plot as well.

#### **Digital media Features** {.tabset .tabset-fade}

There are 5 words features which denote the number and rate of words in title and the content.

##### **Box Plots** {.tabset .tabset-fade}

The box plots enable visualization of the data-set especially in relation to outliers. However considering the large number of data we will plot box plots category wise.

```{r echo=TRUE, warning=FALSE,message=FALSE,error=FALSE,fig.keep='all'}
digital_media_features<-conti_data[6:9]
plot_ly( data=melt(digital_media_features), type = "box",
            split = ~variable,y = ~value)%>%
  layout( title = "Box-Plots of variables")
```

Accept "n_token_content" which tells us the Number of words in the content and "n_token_title" which tells us the Number of words in the title no other variable is well distributed in the entire range. However there is a single outlier present for each of the other variable. Removing that variable gives a good spread to the data. Before removing the observation we will analyse the density plot of word variable.

##### **Density Plots**

The density plots help visualize the characteristics of the distribution including statistical metrics such as mean, standard deviation and kurtosis. It also enables us to visually identify if any relationship exists with the response variable.

```{r echo=TRUE, warning=FALSE,message=FALSE,error=FALSE,fig.keep='all'}

plt<-htmltools::tagList()
index = 1
for (i in colnames(digital_media_features)){
  p<-ggplot(sharing_data,aes(i, fill = "blue"))+geom_density(alpha = 0.5)+ggtitle(paste0("Density Plots of ",i))
ggplotly(p)%>%
  layout(plot_bgcolor="transparent",paper_bgcolor= "transparent")
plt[index]
index = index+1
}
plt
```

We can draw the same conclusion from the density plot as well.

